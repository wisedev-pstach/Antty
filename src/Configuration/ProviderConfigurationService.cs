using Antty.Configuration;
using Antty.Core;
using Antty.Embedding;
using MaIN.Domain.Configuration;
using Spectre.Console;

namespace Antty.Configuration;

public class ProviderConfigurationService : IProviderConfigurationService
{
    public async Task<(IEmbeddingProvider? embeddingProvider, BackendType backendType, string modelName)>
        ConfigureProvidersAsync(AppConfig config)
    {
        AnsiConsole.Write(new Rule("[bold cyan]ü§ñ ASSISTANT CONFIGURATION[/]").RuleStyle("cyan"));
        AnsiConsole.WriteLine();

        var modeChoice = AnsiConsole.Prompt(
            new SelectionPrompt<string>()
                .Title("[cyan]Choose Operating Mode:[/]")
                .PageSize(10)
                .MoreChoicesText("[grey]([yellow]ESC[/] to keep current settings)[/]")
                .AddChoices(new[] {
                    "üíª Local (Offline) - Ollama + Ollama Embeddings",
                    "‚òÅÔ∏è  Cloud (Online) - Cloud Models + OpenAI Embeddings"
                }));

        bool isLocalMode = modeChoice.StartsWith("üíª");

        if (isLocalMode)
        {
            var result = await ConfigureLocalModeAsync(config);
            if (result.embeddingProvider == null) return result;
            return result;
        }
        else
        {
            var result = await ConfigureCloudModeAsync(config);
            if (result.embeddingProvider == null) return result;
            return result;
        }
    }

    private async Task<(IEmbeddingProvider? embeddingProvider, BackendType backendType, string modelName)>
        ConfigureLocalModeAsync(AppConfig config)
    {
        AnsiConsole.MarkupLine("[dim]Configuring for fully offline use...[/]");
        config.EmbeddingProvider = "ollama";

        BackendType backendType = BackendType.Ollama;
        if (!await OllamaManager.EnsureOllamaReadyAsync())
        {
            AnsiConsole.MarkupLine("[red]Cannot proceed without Ollama.[/]");
            return (null, backendType, "");
        }

        const string embeddingModel = "nomic-embed-text";
        if (!await OllamaManager.IsModelInstalledAsync(embeddingModel))
        {
            AnsiConsole.MarkupLine($"[yellow]Embedding model {embeddingModel} not found.[/]");
            if (AnsiConsole.Confirm($"Download {embeddingModel}?", true))
            {
                if (!await OllamaManager.PullModelAsync(embeddingModel))
                {
                    AnsiConsole.MarkupLine("[red]Failed to download embedding model.[/]");
                    return (null, backendType, "");
                }
            }
            else
            {
                AnsiConsole.MarkupLine("[red]Embedding model required for local mode.[/]");
                return (null, backendType, "");
            }
        }
        AnsiConsole.WriteLine();

        string modelName = await ConfigureOllamaModelAsync(config);
        if (string.IsNullOrEmpty(modelName)) return (null, backendType, "");

        config.ChatBackend = backendType.ToString();
        config.ChatModel = modelName;
        config.Save();
        AnsiConsole.WriteLine();

        var embeddingProvider = new OllamaEmbeddingProvider("nomic-embed-text");
        return (embeddingProvider, backendType, modelName);
    }

    private async Task<(IEmbeddingProvider? embeddingProvider, BackendType backendType, string modelName)>
        ConfigureCloudModeAsync(AppConfig config)
    {
        AnsiConsole.MarkupLine("[dim]Configuring for cloud-powered performance...[/]");
        config.EmbeddingProvider = "openai";

        if (string.IsNullOrWhiteSpace(config.ApiKey) || config.ApiKey.StartsWith("sk-YOUR"))
        {
            config.ApiKey = AnsiConsole.Prompt(
                new TextPrompt<string>("[cyan]Enter OpenAI API Key (for Embeddings):[/]")
                    .PromptStyle("green")
                    .Secret());
        }

        var cloudProvider = AnsiConsole.Prompt(
             new SelectionPrompt<string>()
                 .Title("[cyan]Select Chat Provider:[/]")
                 .PageSize(10)
                 .MoreChoicesText("[grey]([yellow]ESC[/] to go back)[/]")
                 .AddChoices(new[] {
                     "OpenAI",
                     "Anthropic",
                     "Google Gemini",
                     "DeepSeek",
                     "XAI (Grok)",
                     "Groq"
                 }));

        string PromptKey(string name, string current)
        {
            if (!string.IsNullOrWhiteSpace(current) && !current.StartsWith("sk-YOUR")) return current;
            return AnsiConsole.Prompt(new TextPrompt<string>($"[cyan]Enter {name} API Key:[/]").Secret());
        }

        string SelectModel(Dictionary<string, string> options)
        {
            var choices = options.Keys.ToList();
            choices.Add("‚å®Ô∏è  Enter custom model ID...");
            var res = AnsiConsole.Prompt(new SelectionPrompt<string>().Title("[cyan]Select Model:[/]").AddChoices(choices));
            if (res.Contains("Enter custom")) return AnsiConsole.Prompt(new TextPrompt<string>("[cyan]Enter Model ID:[/]").Validate(s => !string.IsNullOrWhiteSpace(s)));
            return options[res];
        }

        BackendType backendType;
        string modelName;

        if (cloudProvider == "OpenAI")
        {
            backendType = BackendType.OpenAi;
            modelName = SelectModel(new Dictionary<string, string> {
                { "GPT-5.2 (Flagship)", "gpt-5.2" },
                { "o3 (Reasoning)", "o3" },
                { "GPT-5 Nano (Light)", "gpt-5-nano" },
                { "GPT-4o (Omni)", "gpt-4o" },
                { "o1 (Preview)", "o1" }
            });
        }
        else if (cloudProvider == "Anthropic")
        {
            backendType = BackendType.Anthropic;
            config.AnthropicKey = PromptKey("Anthropic", config.AnthropicKey);
            modelName = SelectModel(new Dictionary<string, string> {
                { "Claude 4.5 Sonnet", "claude-sonnet-4-5-20250929" },
                { "Claude 4.5 Haiku", "claude-haiku-4-5-20251001" },
                { "Claude 4.5 Opus", "claude-opus-4-5-20251101" },
                { "Claude 3.7 Sonnet", "claude-3-7-sonnet" }
            });
        }
        else if (cloudProvider == "Google Gemini")
        {
            backendType = BackendType.Gemini;
            config.GeminiKey = PromptKey("Google Gemini", config.GeminiKey);
            modelName = SelectModel(new Dictionary<string, string> {
                { "Gemini 3.0 Pro", "gemini-3.0-pro-preview" },
                { "Gemini 2.5 Pro", "gemini-2.5-pro" },
                { "Gemini 2.5 Flash", "gemini-2.5-flash" }
            });
        }
        else if (cloudProvider == "DeepSeek")
        {
            backendType = BackendType.DeepSeek;
            config.DeepSeekKey = PromptKey("DeepSeek", config.DeepSeekKey);
            modelName = SelectModel(new Dictionary<string, string> {
                { "DeepSeek R1 (Reasoner)", "deepseek-reasoner" },
                { "DeepSeek V3 (Chat)", "deepseek-chat" }
            });
        }
        else if (cloudProvider == "XAI (Grok)")
        {
            backendType = BackendType.Xai;
            config.XaiKey = PromptKey("XAI (Grok)", config.XaiKey);
            modelName = SelectModel(new Dictionary<string, string> {
                { "Grok-3", "grok-3" },
                { "Grok-2", "grok-2-1212" }
            });
        }
        else if (cloudProvider == "Groq")
        {
            backendType = BackendType.GroqCloud;
            config.GroqKey = PromptKey("Groq", config.GroqKey);
            modelName = SelectModel(new Dictionary<string, string> {
                { "Llama 3.3 70B", "llama-3.3-70b-versatile" },
                { "Llama 3.1 8B", "llama-3.1-8b-instant" },
                { "Mixtral 8x7B", "mixtral-8x7b-32768" }
            });
        }
        else
        {
            return (null, BackendType.Ollama, "");
        }

        config.ChatBackend = backendType.ToString();
        config.ChatModel = modelName;
        config.Save();
        AnsiConsole.WriteLine();

        var embeddingProvider = new OpenAIEmbeddingProvider(config.ApiKey);
        return (embeddingProvider, backendType, modelName);
    }

    private async Task<string> ConfigureOllamaModelAsync(AppConfig config)
    {
        AnsiConsole.WriteLine("[cyan]üîß Select Ollama Chat Model:[/]");

        var installedModels = await OllamaManager.GetInstalledModelsAsync();
        var choices = new List<string>();

        void AddIfInstalled(string display, string modelId)
        {
            if (installedModels.Contains(modelId))
                choices.Add($"[green]‚úì[/] {display} ({modelId})");
            else
                choices.Add($"      {display} ({modelId})");
        }

        AddIfInstalled("Phi 4 Mini (Tool Support)", "phi4-mini");
        AddIfInstalled("Llama 3.1 8B", "llama3.1:8b");
        AddIfInstalled("Llama 3.3 70B", "llama3.3:70b");
        AddIfInstalled("Qwen 2.5 Coder 7B", "qwen2.5-coder:7b");

        if (config.CustomOllamaModels != null && config.CustomOllamaModels.Any())
        {
            foreach (var customModel in config.CustomOllamaModels)
            {
                if (installedModels.Contains(customModel))
                    choices.Add($"[green]‚úì[/] {customModel} (Custom)");
                else
                    choices.Add($"      {customModel} (Custom)");
            }
        }

        choices.Add("‚ûï Add custom model...");

        var selection = AnsiConsole.Prompt(
            new SelectionPrompt<string>()
                .Title("[cyan]Select Model:[/]")
                .PageSize(15)
                .MoreChoicesText("[grey]([yellow]‚Üì‚Üë[/] to navigate, [yellow]ESC[/] to cancel)[/]")
                .AddChoices(choices));

        if (selection.Contains("Add custom"))
        {
            var customModelName = AnsiConsole.Prompt(
                new TextPrompt<string>("[cyan]Enter Ollama Model Name:[/]")
                    .Validate(s => !string.IsNullOrWhiteSpace(s)));

            if (config.CustomOllamaModels == null)
                config.CustomOllamaModels = new List<string>();

            if (!config.CustomOllamaModels.Contains(customModelName))
            {
                config.CustomOllamaModels.Add(customModelName);
                config.Save();
            }

            selection = customModelName;
        }
        else
        {
            selection = System.Text.RegularExpressions.Regex.Match(selection, @"\(([^)]+)\)").Groups[1].Value;
        }

        var modelName = selection.Replace(" (Custom)", "");

        if (await OllamaManager.IsModelInstalledAsync(modelName))
        {
            AnsiConsole.MarkupLine("[green]‚úì[/] Model already downloaded.");
        }
        else
        {
            AnsiConsole.MarkupLine($"[yellow]Model {modelName} not found locally.[/]");
            if (AnsiConsole.Confirm($"Download {modelName}?"))
            {
                if (!await OllamaManager.PullModelAsync(modelName))
                {
                    AnsiConsole.MarkupLine($"[red]Failed to download {modelName}[/]");
                    return "";
                }
            }
            else
                return "";
        }

        return modelName;
    }
}
